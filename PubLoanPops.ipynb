{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PubLoanPops.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xdderekchen/public_loan_data/blob/master/PubLoanPops.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGCL2ls5B_6",
        "colab_type": "text"
      },
      "source": [
        "<h1>ETL for public loan data from FNMA and FRED</h1>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0xSKTFwTSC3",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "A python implementation for processing public loan performance data from FNMA and FRED is presented here.\n",
        "\n",
        "Features:\n",
        "  - handling data from FNMA and FRED\n",
        "  - implemented in both pandas and pyspark\n",
        "  - results can be saved to parquet or sqlite.\n",
        "\n",
        "Data Sources:\n",
        "- FNMA Loan Data can be accessed from https://www.fanniemae.com/portal/funding-the-market/data/loan-performance-data.html\n",
        "- FRED Loan Data can be accessed from http://www.freddiemac.com/research/datasets/sf_loanlevel_dataset.page\n",
        "\n",
        "Ideally the source code should be packed into a python package, however in this early stage of implementation, I find it is easier to put all codes in the multiple sessions all in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G8INjheOAPu",
        "colab_type": "text"
      },
      "source": [
        "# Core Source Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnNzomCQHBfM",
        "colab_type": "text"
      },
      "source": [
        "  ##  Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3IlHVUPHMi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "def showtime(tstart):\n",
        "    \"\"\"\n",
        "    Show runtime duration since tstart\n",
        "\n",
        "    parameters\n",
        "    ----------\n",
        "    tstart: datetime, since this time, the duration is calculated\n",
        "    Returns\n",
        "    -------\n",
        "    out : duration in ms\n",
        "    \"\"\"\n",
        "    te = time.time()\n",
        "    return f\"{int((te - tstart) * 1000)} ms\"\n",
        "\n",
        "def decorator_time(method):\n",
        "    \"\"\"\n",
        "    Decorator function. Show runtime duration for the wrapped function.\n",
        "    \"\"\"\n",
        "    def timed(*args, **kw):\n",
        "        ts = time.time()\n",
        "        result = method(*args, **kw)\n",
        "        te = time.time()\n",
        "        if 'log_time' in kw:\n",
        "            name = kw.get('log_name', method.__name__.upper())\n",
        "            kw['log_time'][name] = f\"{int((te - ts) * 1000)} ms\"\n",
        "        else:\n",
        "            print('%r  %2.2f ms' % \\\n",
        "                  (method.__name__, (te - ts) * 1000)\n",
        "                  )\n",
        "        return result\n",
        "    return timed\n",
        "\n",
        "\n",
        "def compute_amortization(principals, monthly_rates, terms,  start_period = 0, end_period = None):\n",
        "    \"\"\"\n",
        "    Compute amortization of loans\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    principals : scalar or array_like of shape(M, )\n",
        "        pricipals of loans\n",
        "    monthly_rates: scalar or array_like if  principals is a scalar\n",
        "                   or\n",
        "                   array_like or matrix_like if principals is an array_like\n",
        "        For FRM, one Rate for each loan\n",
        "        For ARM, one full time series for each loan\n",
        "    \n",
        "    terms:  scalar or array_like of shape(M, )\n",
        "    loan terms, type should match that of principals\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    out : ndarray (M, N)\n",
        "\n",
        "    \"\"\"\n",
        "    num_loans = 1\n",
        "    if isinstance(principals, pd.Series):\n",
        "       principals = principals.values\n",
        "    elif np.ndim(principals) == 0:\n",
        "       principals = [principals]\n",
        "       \n",
        "    #assume principals is np.array\n",
        "    num_loans = len(principals)\n",
        "\n",
        "    if isinstance(monthly_rates, pd.Series):\n",
        "       monthly_rates = monthly_rates.values\n",
        "    elif np.ndim(principals) == 0:\n",
        "       monthly_rates = [monthly_rates]\n",
        "\n",
        "    if isinstance(terms, pd.Series):\n",
        "       terms = terms.values\n",
        "    elif np.ndim(terms) == 0:\n",
        "       terms = [terms]\n",
        "    \n",
        "    num_month = terms.max()\n",
        "    mini_term = terms.min()\n",
        "    if end_period is not None:\n",
        "      num_month = min(num_month, max(1, (end_period - start_period)))\n",
        "    \n",
        "    upb_matrix = np.zeros((num_month, num_loans))\n",
        "    the_payment = principals * (monthly_rates / (1 - (1 + monthly_rates) ** (-terms)))\n",
        "    \n",
        "    current_upb = principals\n",
        "    if start_period > 0:\n",
        "       current_upb = principals\n",
        "       for t in range(1, start_period+1):\n",
        "          pp_payment = the_payment - current_upb * monthly_rates\n",
        "          current_upb = current_upb - pp_payment\n",
        "    \n",
        "    upb_matrix[0, :] = current_upb\n",
        "      \n",
        "    i = 1\n",
        "    for t in range(start_period+1, start_period +num_month ):\n",
        "       isbeyondTerm = np.greater(t , terms)\n",
        "       pp_payment = the_payment - upb_matrix[i-1, :] * monthly_rates\n",
        "       upb_matrix[i, :] = (upb_matrix[i-1, :] - pp_payment) \n",
        "       if t >= mini_term:\n",
        "          iswithinTerm = np.greater( terms, t).astype(int)\n",
        "          isbeyondTerm = np.greater(t , terms).astype(int)\n",
        "          upb_matrix[i, :] = upb_matrix[i, :] * np.array(iswithinTerm) + (-999) * isbeyondTerm\n",
        "       i = i +  1\n",
        "    return upb_matrix.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmThbPdkR0e9",
        "colab_type": "text"
      },
      "source": [
        "  ## class Data_Schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyD3vWYnUBN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Data_Schema(object):\n",
        "    _AcquisitionSchema_FNMA = {\"LOAN_ID\":         {\"dtype\": \"string\"},\n",
        "                          \"ORIG_CHN\":        {\"dtype\": \"string\"},\n",
        "                          \"SellerName\":      {\"dtype\": \"string\", \"drop\":True},\n",
        "                          \"ORIG_RT\":         {\"dtype\": \"float\"},\n",
        "                          \"ORIG_AMT\":        {\"dtype\": \"double\"},\n",
        "                          \"ORIG_TRM\":        {\"dtype\": \"int\" },\n",
        "                          \"ORIG_DTE\":        {\"dtype\": \"date\", \"format\":\"%m/%Y\", \"format2\":\"MM/yyyy\"},\n",
        "                          \"FRST_DTE\":        {\"dtype\": \"date\", \"format\":\"%m/%Y\", \"format2\":\"MM/yyyy\"},\n",
        "                          \"OLTV\":            {\"dtype\": \"float\", \"default\": 0},\n",
        "                          \"OCLTV\":           {\"dtype\": \"float\", \"default\": 0},\n",
        "                          \"NUM_BO\":          {\"dtype\": \"int\", \"default\": -1},\n",
        "                          \"DTI\":             {\"dtype\": \"int\", \"default\": -1},\n",
        "                          \"CSCORE_B\":        {\"dtype\": \"float\", \"default\": -1},\n",
        "                          \"FTHB_FLG\":        {\"dtype\": \"string\"},\n",
        "                          \"PURPOSE\":         {\"dtype\": \"string\"},\n",
        "                          \"PROP_TYP\":        {\"dtype\": \"string\"},\n",
        "                          \"NUM_UNIT\":        {\"dtype\": \"int\", \"default\": -1},\n",
        "                          \"OCC_STAT\":        {\"dtype\": \"string\"},\n",
        "                          \"STATE\":           {\"dtype\": \"string\"},\n",
        "                          \"ZIP_3\":           {\"dtype\": \"string\"},\n",
        "                          \"MI_PCT\":          {\"dtype\": \"int\", \"default\": 0},\n",
        "                          \"Product_Type\":    {\"dtype\": \"string\"},\n",
        "                          \"CSCORE_C\":        {\"dtype\": \"int\", \"default\": -1},\n",
        "                          \"MI_TYPE\":         {\"dtype\": \"string\", \"default\": \"0\"},\n",
        "                          \"RELOCATION_FLG\":  {\"dtype\": \"string\"}\n",
        "                          }\n",
        "\n",
        "    # schema of Performance Data\n",
        "    _PerformanceSchema_FNMA = {\"LOAN_ID\":         {\"dtype\": \"string\"},\n",
        "                          \"ACT_DTE\":         {\"dtype\": \"date\", \"format\":\"%d/%m/%Y\", \"format2\":\"MM/dd/yyyy\"},\n",
        "                          \"SERVICER\":        {\"dtype\": \"string\", \"drop\":True},\n",
        "                          \"LAST_RT\":         {\"dtype\": \"float\"},\n",
        "                          \"LAST_UPB\":        {\"dtype\": \"double\"},\n",
        "                          \"LOAN_AGE\":        {\"dtype\": \"int\"},\n",
        "                          \"Months_To_Legal_Mat\": {\"dtype\": \"int\", \"default\": -1},\n",
        "                          \"Adj_Month_To_Mat\": {\"dtype\": \"int\", \"default\": -1},\n",
        "                          \"Maturity_Date\":   {\"dtype\": \"date\",                      \"format2\":\"MM/yyyy\"},\n",
        "                          \"MSA\":             {\"dtype\": \"string\", \"drop\":True},\n",
        "                          \"DLQ_STATUS\":      {\"dtype\": \"string\"},\n",
        "                          \"MOD_FLAG\":        {\"dtype\": \"string\", \"drop\":True},\n",
        "                          \"ZB_CODE\":         {\"dtype\": \"string\", \"drop\":True},\n",
        "                          \"ZB_DTE\":          {\"dtype\": \"date\",   \"drop\":True,        \"format2\":\"MM/yyyy\"    },\n",
        "                          \"LPI_DTE\":         {\"dtype\": \"date\",   \"drop\":True,        \"format2\":\"MM/dd/yyyy\" },\n",
        "                          \"FCC_DTE\":         {\"dtype\": \"date\",   \"drop\":True,        \"format2\":\"MM/dd/yyyy\" },\n",
        "                          \"DISP_DTE\":         {\"dtype\": \"date\",   \"drop\":True,        \"format2\":\"MM/dd/yyyy\" },\n",
        "                          \"FCC_COST\":        {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"PP_COST\":         {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"AR_COST\":         {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"IE_COST\":         {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"TAX_COST\":        {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"NS_PROCS\":        {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"CE_PROCS\":        {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"RMW_PROCS\":       {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"O_PROCS\":         {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"NON_INT_UPB\":     {\"dtype\": \"float\"},\n",
        "                          \"PRIN_FORG_UPB_FHFA\": {\"dtype\": \"float\"},\n",
        "                          \"REPCH_FLAG\":      {\"dtype\": \"string\"},\n",
        "                          \"PRIN_FORG_UPB_OTH\": {\"dtype\": \"string\"},\n",
        "                          \"TRANSFER_FLG\":    {\"dtype\": \"string\"},\n",
        "                          }\n",
        "    _AcquisitionSchema_FRED = { \"CSCORE_B\":        {\"dtype\": \"float\", \"default\": -1},\n",
        "                               \"FRST_DTE\":        {\"dtype\": \"date\", \"format\":\"%Y/%m\", \"format2\":\"yyyyMM\"},\n",
        "                              \"FTHB_FLG\":        {\"dtype\": \"string\"},\n",
        "                              \"MAT_DTE\" :        {\"dtype\": \"date\", \"format\":\"%Y/%m\", \"format2\":\"yyyyMM\"},\n",
        "                              \"MSA\":             {\"dtype\": \"string\", \"drop\":True},\n",
        "                              \"MI_PCT\":          {\"dtype\": \"int\", \"default\": 0},\n",
        "                              \"NUM_UNIT\":        {\"dtype\": \"int\", \"default\": -1},\n",
        "                               \"OCC_STAT\":        {\"dtype\": \"string\"},\n",
        "                              \"OCLTV\":           {\"dtype\": \"float\", \"default\": 0},\n",
        "                              \"DTI\":             {\"dtype\": \"int\", \"default\": -1},\n",
        "                              \"ORIG_AMT\":        {\"dtype\": \"double\"},\n",
        "                              \"OLTV\":            {\"dtype\": \"float\", \"default\": 0},\n",
        "                              \"ORIG_RT\":         {\"dtype\": \"float\"},\n",
        "                              \"ORIG_CHN\":        {\"dtype\": \"string\"},\n",
        "                              \"ppmt_pnlty\" :        {\"dtype\": \"string\"},\n",
        "                              \"Product_Type\":    {\"dtype\": \"string\"},\n",
        "                              \"STATE\":           {\"dtype\": \"string\"},\n",
        "                              \"PROP_TYP\":        {\"dtype\": \"string\"},\n",
        "                              \"ZIP_3\":           {\"dtype\": \"string\"},\n",
        "                              \"LOAN_ID\":         {\"dtype\": \"string\"},\n",
        "                              \"PURPOSE\":         {\"dtype\": \"string\"},\n",
        "                              \"ORIG_TRM\":        {\"dtype\": \"int\" },\n",
        "                              \"NUM_BO\":          {\"dtype\": \"int\", \"default\": -1},\n",
        "                              \"SellerName\":      {\"dtype\": \"string\", \"drop\":True},\n",
        "                              \"SERVICER\":        {\"dtype\": \"string\", \"drop\":True},\n",
        "                              \"flag_sc\":        {\"dtype\": \"string\", \"drop\":True}\n",
        "                          }\n",
        "\n",
        "    # schema of Performance Data\n",
        "    _PerformanceSchema_FRED = {\"LOAN_ID\":         {\"dtype\": \"string\"},\n",
        "                          \"ACT_DTE\":         {\"dtype\": \"date\", \"format\":\"%Y/%m/%d\", \"format2\":\"yyyyMM\"},                       \n",
        "                          \"LAST_UPB\":        {\"dtype\": \"double\"},\n",
        "                          \"DLQ_STATUS\":      {\"dtype\": \"string\"},\n",
        "                          \"LOAN_AGE\":        {\"dtype\": \"int\"},\n",
        "                          \"Months_To_Legal_Mat\": {\"dtype\": \"int\", \"default\": -1},\n",
        "                          \"REPCH_FLAG\":      {\"dtype\": \"string\"},\n",
        "                          \"MOD_FLAG\":        {\"dtype\": \"string\", \"drop\":True},\n",
        "                          \"ZB_CODE\":         {\"dtype\": \"string\", \"drop\":True},\n",
        "                          \"ZB_DTE\":          {\"dtype\": \"date\",   \"drop\":True,        \"format2\":\"yyyyMM\"    },\n",
        "                          \"LAST_RT\":         {\"dtype\": \"float\"},\n",
        "                          \"NON_INT_UPB\":     {\"dtype\": \"float\"},\n",
        "                          \"LPI_DTE\":         {\"dtype\": \"date\",   \"drop\":True,        \"format2\":\"yyyyMM\" },\n",
        "                          \"CE_PROCS\":        {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"NS_PROCS\":        {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"RMW_PROCS\":       {\"dtype\": \"float\", \"drop\":True},  \n",
        "                          \"EXpenses\":        {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"LEGAL_COST\":       {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"MAINT_COST\":       {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"TAX_COST\":        {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"MISC_COST\":       {\"dtype\": \"float\", \"drop\":True},\n",
        "                          \"ACTUAL_LOSS\":     {\"dtype\": \"float\", \"drop\":False},\n",
        "                          \"MOD_LOSS\":        {\"dtype\": \"float\", \"drop\":False},\n",
        "                          \"STEPMOD_IND\":     {\"dtype\": \"string\", \"drop\":True},\n",
        "                          \"DPM_IND\":         {\"dtype\": \"string\", \"drop\":True},\n",
        "                          \"ELTV\"   :         {\"dtype\": \"float\", \"drop\":True}\n",
        "                          }\n",
        "    def __init__(self, agency=\"FNMA\"):\n",
        "        self.agency = agency\n",
        "   \n",
        "    def AcquisitionSchema(self):\n",
        "       if self.agency == \"FNMA\":\n",
        "          return self._AcquisitionSchema_FNMA;\n",
        "       else:\n",
        "          return self._AcquisitionSchema_FRED;\n",
        "\n",
        "    def PerformanceSchema(self):\n",
        "       if  self.agency == \"FNMA\":\n",
        "          return self._PerformanceSchema_FNMA;\n",
        "       else:\n",
        "          return self._PerformanceSchema_FRED;\n",
        "\n",
        "    @staticmethod\n",
        "    def columnType(v):\n",
        "        vout = str\n",
        "        dtype = v.get('dtype')\n",
        "        if dtype == \"float\":\n",
        "            vout = np.float32\n",
        "        elif dtype == \"double\":\n",
        "            vout = np.float64\n",
        "        elif dtype  == \"int\":\n",
        "            value = v.get('default')\n",
        "            if value is None:\n",
        "                vout = np.int32\n",
        "            else:\n",
        "                vout = np.float32\n",
        "        elif dtype  == \"string\":\n",
        "            vout = str\n",
        "        elif dtype == \"date\":\n",
        "            vout = \"date\"\n",
        "        else:\n",
        "            vout = \"other\"\n",
        "        return vout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zSZwhWcUQIz",
        "colab_type": "text"
      },
      "source": [
        "## Class Agency_Loan\n",
        " pandas version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2RNeIPZZ7N7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sqlalchemy as db\n",
        "\n",
        "class Agency_Loan(object):\n",
        "    '''processing public loan data from Fannie Mae and FRED'''\n",
        "    def __init__(self, agency, acqYYYYQQ, stageFolder=None,  acquisition_file=None, performance_file=None):\n",
        "        self.Data_Schema = Data_Schema(agency)\n",
        "        self.acqYYYYQQ = acqYYYYQQ\n",
        "        self.acquisition_file = acquisition_file\n",
        "        self.performance_file = performance_file\n",
        "        self.stageFolder = stageFolder\n",
        "        self._Loan_Data = None\n",
        "        self._Performance_Data = None\n",
        "\n",
        "    @property\n",
        "    def Loan_Data(self):\n",
        "        return self._Loan_Data\n",
        "\n",
        "    @Loan_Data.setter\n",
        "    def Loan_Data(self, x):\n",
        "        self._Loan_Data = x\n",
        "\n",
        "    @property\n",
        "    def Performance_Data(self):\n",
        "        return self._Performance_Data\n",
        "\n",
        "    @Performance_Data.setter\n",
        "    def Performance_Data(self, x):\n",
        "        self._Performance_Data = x\n",
        "\n",
        "    def read_data_acquisition(self, acquisition_file=None):\n",
        "        '''\n",
        "        read and pre-process acqusition data\n",
        "        '''\n",
        "        if acquisition_file is not None:\n",
        "            self.acquisition_file = acquisition_file\n",
        "\n",
        "        col_names = [ k for k in self.Data_Schema.AcquisitionSchema().keys()]\n",
        "        col_dtype = { k: Data_Schema.columnType(v) for k, v in self.Data_Schema.AcquisitionSchema().items() \\\n",
        "                         if Data_Schema.columnType(v) not in ( \"other\", \"date\") }\n",
        "\n",
        "        parse_dates =[ k for k, v in self.Data_Schema.AcquisitionSchema().items() \\\n",
        "                         if Data_Schema.columnType(v) == \"date\" ]\n",
        "\n",
        "        #print(parse_dates)\n",
        "\n",
        "        df = pd.read_csv(self.acquisition_file, delimiter ='|', header=None,\n",
        "                    names=col_names,\n",
        "                    dtype=col_dtype,  parse_dates = parse_dates\n",
        "                    )\n",
        "        df['OCLTV'] = df['OCLTV'].fillna(df['OLTV'])\n",
        "        self.Loan_Data = df\n",
        "        return None\n",
        "\n",
        "\n",
        "    def read_data_performance(self, performance_file=None):\n",
        "        '''\n",
        "        read and pre-process performance data\n",
        "        '''\n",
        "        if performance_file is not None:\n",
        "            self.performance_file = performance_file\n",
        "\n",
        "        col_names = [k for k in self.Data_Schema.PerformanceSchema().keys()]\n",
        "        col_dtype = {k: Data_Schema.columnType(v) for k, v in self.Data_Schema.PerformanceSchema().items() \\\n",
        "                     if Data_Schema.columnType(v) not in (\"other\", \"date\")}\n",
        "\n",
        "        parse_dates = [k for k, v in self.Data_Schema.PerformanceSchema().items() \\\n",
        "                       if Data_Schema.columnType(v) == \"date\"]\n",
        "\n",
        "        df = pd.read_csv(self.performance_file, delimiter='|', header=None,\n",
        "                         names=col_names,\n",
        "                         dtype=col_dtype,\n",
        "                         parse_dates=parse_dates\n",
        "                         )\n",
        "\n",
        "        for k, v in self.Data_Schema.PerformanceSchema().items():\n",
        "            value = v.get('default')\n",
        "            if value is not None:\n",
        "                if v.get(\"dtype\") == \"int\":\n",
        "                    df[k] = df[k].fillna(value).astype(\"int32\")\n",
        "                else:\n",
        "                    df[k] = df[k].fillna(value)\n",
        "\n",
        "        self.Performance_Data = df\n",
        "        return None\n",
        "        #df[\"ACQ\"] = self.acqYYYYQQ\n",
        "        #if self.resultFolder is not None:\n",
        "        #   df.to_parquet(self.resultFolder + \"\\\\performance.parquet\", engine='pyarrow', partition_cols=['ACQ'])\n",
        "      \n",
        "    @decorator_time\n",
        "    def read_data_performance_chunk(self, performance_file=None, **kwargs):\n",
        "        '''\n",
        "        read and pre-process performance data\n",
        "\n",
        "        df.write.mode('append').parquet('parquet_data_file')\n",
        "\n",
        "        '''\n",
        "        if performance_file is not None:\n",
        "            self.performance_file = performance_file\n",
        "\n",
        "        col_names = [k for k in self.Data_Schema.PerformanceSchema().keys()]\n",
        "        col_dtype = {k: Data_Schema.columnType(v) for k, v in self.Data_Schema.PerformanceSchema().items() \\\n",
        "                     if Data_Schema.columnType(v) not in (\"other\", \"date\")}\n",
        "\n",
        "        parse_dates = [k for k, v in self.Data_Schema.PerformanceSchema().items() \\\n",
        "                       if Data_Schema.columnType(v) == \"date\"]\n",
        "\n",
        "        \n",
        "        db_engine_file = 'sqlite:///' + self.stageFolder + \"\\\\performance10.db\"\n",
        "        db_engine = db.create_engine(db_engine_file)\n",
        "\n",
        "        chunksize = 10000\n",
        "        loop = 0\n",
        "        create_it = True\n",
        "        pqwriter = None\n",
        "        for df in pd.read_csv(self.performance_file, delimiter='|', header=None,\n",
        "                         chunksize=chunksize, iterator=True,\n",
        "                         names=col_names,\n",
        "                         dtype=col_dtype,\n",
        "                         parse_dates=parse_dates\n",
        "                         ):\n",
        "            loop = loop + 1\n",
        "            #print(loop)\n",
        "            for k, v in self.Data_Schema.PerformanceSchema().items():\n",
        "                value = v.get('default')\n",
        "                if value is not None:\n",
        "                    if v.get(\"dtype\") == \"int\":\n",
        "                       df[k] = df[k].fillna(value).astype(\"int32\")\n",
        "                    else:\n",
        "                       df[k] = df[k].fillna(value)\n",
        "\n",
        "\n",
        "            #print(\"save_sqlite\")\n",
        "            if create_it:\n",
        "               df.to_sql(\"perf\", db_engine, if_exists='replace')\n",
        "               create_it = False\n",
        "            else:\n",
        "               df.to_sql(\"perf\", db_engine, if_exists='append')\n",
        "\n",
        "        if pqwriter:\n",
        "            pqwriter.close()\n",
        "        \n",
        "        ##self.SQLite2Parquet(\"performance9.db\",  \"performance.parquet\")\n",
        "        return d\n",
        "\n",
        "    def SQLite2Parquet(self, dbFile, parquetFile):\n",
        "        print(\"SQLite2Parquet\")\n",
        "        db_engine_file = 'sqlite:///' + self.resultFolder + \"\\\\\" + dbFile\n",
        "        db_engine = db.create_engine(db_engine_file)\n",
        "        df =  pd.read_sql_query(\"select * from  perf \", db_engine )\n",
        "        #db_engine.close()\n",
        "        print(\"finsing reading\")\n",
        "        df[\"ACQ\"] = self.acqYYYYQQ\n",
        "        df.to_parquet(self.resultFolder + \"\\\\\" + parquetFile, engine='pyarrow', partition_cols=['ACQ'])\n",
        "        return True\n",
        "\n",
        "    def save_as_parquet(self, resultFolder= None, Loan_Data =True, Performance_Data=True):\n",
        "       if resultFolder is not None:\n",
        "            if os.path.isdir(resultFolder):\n",
        "              try:\n",
        "                 if (Loan_Data == True) and (self.Loan_Data is not None):\n",
        "                   self.Loan_Data.write.mode('overwrite').parquet(resultFolder + \"/output/FNMA/Loan.parquet/ACQ=\" + self.acqYYYYQQ)\n",
        "                 if (Performance_Data == True) and (self.Performance_Data is not None):\n",
        "                   self.Performance_Data.write.mode('overwrite').parquet(resultFolder + \"/output/FNMA/LoanPerformance.parquet/ACQ=\" + self.acqYYYYQQ)\n",
        "              except Exception as err:\n",
        "                  print(\"save_as_parquet: Error:  {0}\".format(err))\n",
        "\n",
        "    def clear_data(self):\n",
        "       if _Loan_Data is not None:\n",
        "         del _Loan_Data\n",
        "         _Loan_Data = None\n",
        "       if _Performance_Data is not None:\n",
        "         del _Performance_Data\n",
        "         _Performance_Data = None\n",
        "       \n",
        "    def compute_schd_upb(self, monthCount, outAsMatrix=True, loan_Pandas_Dataframe=None):\n",
        "          '''\n",
        "          Calculate the scheduled UPB based on the Loan_Data[\"ORIG_AMT\", \"ORIG_RT\", \"ORIG_TRM\"]\n",
        "\n",
        "          Parameters\n",
        "          ----------\n",
        "          monthCount: int, sepcify the period to get UPB.\n",
        "          outAsMatrix : default to be True, returning \"matrix\" or  \"pandas_df\"\n",
        "       \n",
        "          Returns\n",
        "          -------\n",
        "          out : ndarray (loanCount, monthCount), pandas dataframe\n",
        "          '''\n",
        "          if loan_Pandas_Dataframe  is None:\n",
        "             sub_df = self._Loan_Data\n",
        "          else:\n",
        "             sub_df = loan_Pandas_Dataframe\n",
        "         \n",
        "          upb_matrix = compute_amortization(principals    = sub_df[\"ORIG_AMT\"], \n",
        "                                            monthly_rates = sub_df[\"ORIG_RT\"] / 1200,\n",
        "                                            terms         = sub_df[\"ORIG_TRM\"],\n",
        "                                            start_period  = 0, \n",
        "                                            end_period    = monthCount)\n",
        "          \n",
        "          if outAsMatrix == True:\n",
        "             return upb_matrix\n",
        "          else:\n",
        "             upb_array = upb_matrix.flatten()\n",
        "             r,c = upb_matrix.shape\n",
        "             ages_value = np.arange(c)\n",
        "             ages_value = np.tile(ages_value, r)\n",
        "             loanids = np.repeat(sub_df[\"LOAN_ID\"].values, c)\n",
        "             upb_array = pd.DataFrame({\"LOAN_ID\": loanids,\n",
        "                           \"LOAN_AGE\": ages_value,\n",
        "                           \"SCHD_UPB\": upb_array})\n",
        "             \n",
        "             return (upb_array)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kJmCScvUrdI",
        "colab_type": "text"
      },
      "source": [
        "## Test Driver for class Agency_Loan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMLejp5SUDxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Case 1, FNMA loan\n",
        "myobj = Agency_Loan(agency=\"FNMA\", acqYYYYQQ = \"2000Q1\", stageFolder = \"/content/drive/My Drive/ML_Data/stock\",\n",
        "                                          acquisition_file = \"/content/drive/My Drive/ML_Data/stock/Acquisition_2000Q1.txt\",\n",
        "                                   performance_file = \"/content/drive/My Drive/ML_Data/stock/Performance_2000Q1.txt\" )\n",
        "loandf  = myobj.read_data_acquisition()\n",
        "perfdf = myobj.read_data_performance_chunk()\n",
        "upb =    myobj.compute_schd_upb(monthCount =12, outAsMatrix=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfQdoaHJwrNW",
        "colab_type": "text"
      },
      "source": [
        "# Install PySpark and configure the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeE7bsNjTB7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gVVr4gYaAX_",
        "colab_type": "text"
      },
      "source": [
        "# Class PUBLIC_LOAN_FNMA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4LP1KmjxFqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "4535f113-1c22-4569-8953-ad0dab99b10f"
      },
      "source": [
        "! git clone https://github.com/xdderekchen/public_loan_data.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'public_loan_data'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/102)\u001b[K\rremote: Counting objects:   1% (2/102)\u001b[K\rremote: Counting objects:   2% (3/102)\u001b[K\rremote: Counting objects:   3% (4/102)\u001b[K\rremote: Counting objects:   4% (5/102)\u001b[K\rremote: Counting objects:   5% (6/102)\u001b[K\rremote: Counting objects:   6% (7/102)\u001b[K\rremote: Counting objects:   7% (8/102)\u001b[K\rremote: Counting objects:   8% (9/102)\u001b[K\rremote: Counting objects:   9% (10/102)\u001b[K\rremote: Counting objects:  10% (11/102)\u001b[K\rremote: Counting objects:  11% (12/102)\u001b[K\rremote: Counting objects:  12% (13/102)\u001b[K\rremote: Counting objects:  13% (14/102)\u001b[K\rremote: Counting objects:  14% (15/102)\u001b[K\rremote: Counting objects:  15% (16/102)\u001b[K\rremote: Counting objects:  16% (17/102)\u001b[K\rremote: Counting objects:  17% (18/102)\u001b[K\rremote: Counting objects:  18% (19/102)\u001b[K\rremote: Counting objects:  19% (20/102)\u001b[K\rremote: Counting objects:  20% (21/102)\u001b[K\rremote: Counting objects:  21% (22/102)\u001b[K\rremote: Counting objects:  22% (23/102)\u001b[K\rremote: Counting objects:  23% (24/102)\u001b[K\rremote: Counting objects:  24% (25/102)\u001b[K\rremote: Counting objects:  25% (26/102)\u001b[K\rremote: Counting objects:  26% (27/102)\u001b[K\rremote: Counting objects:  27% (28/102)\u001b[K\rremote: Counting objects:  28% (29/102)\u001b[K\rremote: Counting objects:  29% (30/102)\u001b[K\rremote: Counting objects:  30% (31/102)\u001b[K\rremote: Counting objects:  31% (32/102)\u001b[K\rremote: Counting objects:  32% (33/102)\u001b[K\rremote: Counting objects:  33% (34/102)\u001b[K\rremote: Counting objects:  34% (35/102)\u001b[K\rremote: Counting objects:  35% (36/102)\u001b[K\rremote: Counting objects:  36% (37/102)\u001b[K\rremote: Counting objects:  37% (38/102)\u001b[K\rremote: Counting objects:  38% (39/102)\u001b[K\rremote: Counting objects:  39% (40/102)\u001b[K\rremote: Counting objects:  40% (41/102)\u001b[K\rremote: Counting objects:  41% (42/102)\u001b[K\rremote: Counting objects:  42% (43/102)\u001b[K\rremote: Counting objects:  43% (44/102)\u001b[K\rremote: Counting objects:  44% (45/102)\u001b[K\rremote: Counting objects:  45% (46/102)\u001b[K\rremote: Counting objects:  46% (47/102)\u001b[K\rremote: Counting objects:  47% (48/102)\u001b[K\rremote: Counting objects:  48% (49/102)\u001b[K\rremote: Counting objects:  49% (50/102)\u001b[K\rremote: Counting objects:  50% (51/102)\u001b[K\rremote: Counting objects:  51% (53/102)\u001b[K\rremote: Counting objects:  52% (54/102)\u001b[K\rremote: Counting objects:  53% (55/102)\u001b[K\rremote: Counting objects:  54% (56/102)\u001b[K\rremote: Counting objects:  55% (57/102)\u001b[K\rremote: Counting objects:  56% (58/102)\u001b[K\rremote: Counting objects:  57% (59/102)\u001b[K\rremote: Counting objects:  58% (60/102)\u001b[K\rremote: Counting objects:  59% (61/102)\u001b[K\rremote: Counting objects:  60% (62/102)\u001b[K\rremote: Counting objects:  61% (63/102)\u001b[K\rremote: Counting objects:  62% (64/102)\u001b[K\rremote: Counting objects:  63% (65/102)\u001b[K\rremote: Counting objects:  64% (66/102)\u001b[K\rremote: Counting objects:  65% (67/102)\u001b[K\rremote: Counting objects:  66% (68/102)\u001b[K\rremote: Counting objects:  67% (69/102)\u001b[K\rremote: Counting objects:  68% (70/102)\u001b[K\rremote: Counting objects:  69% (71/102)\u001b[K\rremote: Counting objects:  70% (72/102)\u001b[K\rremote: Counting objects:  71% (73/102)\u001b[K\rremote: Counting objects:  72% (74/102)\u001b[K\rremote: Counting objects:  73% (75/102)\u001b[K\rremote: Counting objects:  74% (76/102)\u001b[K\rremote: Counting objects:  75% (77/102)\u001b[K\rremote: Counting objects:  76% (78/102)\u001b[K\rremote: Counting objects:  77% (79/102)\u001b[K\rremote: Counting objects:  78% (80/102)\u001b[K\rremote: Counting objects:  79% (81/102)\u001b[K\rremote: Counting objects:  80% (82/102)\u001b[K\rremote: Counting objects:  81% (83/102)\u001b[K\rremote: Counting objects:  82% (84/102)\u001b[K\rremote: Counting objects:  83% (85/102)\u001b[K\rremote: Counting objects:  84% (86/102)\u001b[K\rremote: Counting objects:  85% (87/102)\u001b[K\rremote: Counting objects:  86% (88/102)\u001b[K\rremote: Counting objects:  87% (89/102)\u001b[K\rremote: Counting objects:  88% (90/102)\u001b[K\rremote: Counting objects:  89% (91/102)\u001b[K\rremote: Counting objects:  90% (92/102)\u001b[K\rremote: Counting objects:  91% (93/102)\u001b[K\rremote: Counting objects:  92% (94/102)\u001b[K\rremote: Counting objects:  93% (95/102)\u001b[K\rremote: Counting objects:  94% (96/102)\u001b[K\rremote: Counting objects:  95% (97/102)\u001b[K\rremote: Counting objects:  96% (98/102)\u001b[K\rremote: Counting objects:  97% (99/102)\u001b[K\rremote: Counting objects:  98% (100/102)\u001b[K\rremote: Counting objects:  99% (101/102)\u001b[K\rremote: Counting objects: 100% (102/102)\u001b[K\rremote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/98)\u001b[K\rremote: Compressing objects:   2% (2/98)\u001b[K\rremote: Compressing objects:   3% (3/98)\u001b[K\rremote: Compressing objects:   4% (4/98)\u001b[K\rremote: Compressing objects:   5% (5/98)\u001b[K\rremote: Compressing objects:   6% (6/98)\u001b[K\rremote: Compressing objects:   7% (7/98)\u001b[K\rremote: Compressing objects:   8% (8/98)\u001b[K\rremote: Compressing objects:   9% (9/98)\u001b[K\rremote: Compressing objects:  10% (10/98)\u001b[K\rremote: Compressing objects:  11% (11/98)\u001b[K\rremote: Compressing objects:  12% (12/98)\u001b[K\rremote: Compressing objects:  13% (13/98)\u001b[K\rremote: Compressing objects:  14% (14/98)\u001b[K\rremote: Compressing objects:  15% (15/98)\u001b[K\rremote: Compressing objects:  16% (16/98)\u001b[K\rremote: Compressing objects:  17% (17/98)\u001b[K\rremote: Compressing objects:  18% (18/98)\u001b[K\rremote: Compressing objects:  19% (19/98)\u001b[K\rremote: Compressing objects:  20% (20/98)\u001b[K\rremote: Compressing objects:  21% (21/98)\u001b[K\rremote: Compressing objects:  22% (22/98)\u001b[K\rremote: Compressing objects:  23% (23/98)\u001b[K\rremote: Compressing objects:  24% (24/98)\u001b[K\rremote: Compressing objects:  25% (25/98)\u001b[K\rremote: Compressing objects:  26% (26/98)\u001b[K\rremote: Compressing objects:  27% (27/98)\u001b[K\rremote: Compressing objects:  28% (28/98)\u001b[K\rremote: Compressing objects:  29% (29/98)\u001b[K\rremote: Compressing objects:  30% (30/98)\u001b[K\rremote: Compressing objects:  31% (31/98)\u001b[K\rremote: Compressing objects:  32% (32/98)\u001b[K\rremote: Compressing objects:  33% (33/98)\u001b[K\rremote: Compressing objects:  34% (34/98)\u001b[K\rremote: Compressing objects:  35% (35/98)\u001b[K\rremote: Compressing objects:  36% (36/98)\u001b[K\rremote: Compressing objects:  37% (37/98)\u001b[K\rremote: Compressing objects:  38% (38/98)\u001b[K\rremote: Compressing objects:  39% (39/98)\u001b[K\rremote: Compressing objects:  40% (40/98)\u001b[K\rremote: Compressing objects:  41% (41/98)\u001b[K\rremote: Compressing objects:  42% (42/98)\u001b[K\rremote: Compressing objects:  43% (43/98)\u001b[K\rremote: Compressing objects:  44% (44/98)\u001b[K\rremote: Compressing objects:  45% (45/98)\u001b[K\rremote: Compressing objects:  46% (46/98)\u001b[K\rremote: Compressing objects:  47% (47/98)\u001b[K\rremote: Compressing objects:  48% (48/98)\u001b[K\rremote: Compressing objects:  50% (49/98)\u001b[K\rremote: Compressing objects:  51% (50/98)\u001b[K\rremote: Compressing objects:  52% (51/98)\u001b[K\rremote: Compressing objects:  53% (52/98)\u001b[K\rremote: Compressing objects:  54% (53/98)\u001b[K\rremote: Compressing objects:  55% (54/98)\u001b[K\rremote: Compressing objects:  56% (55/98)\u001b[K\rremote: Compressing objects:  57% (56/98)\u001b[K\rremote: Compressing objects:  58% (57/98)\u001b[K\rremote: Compressing objects:  59% (58/98)\u001b[K\rremote: Compressing objects:  60% (59/98)\u001b[K\rremote: Compressing objects:  61% (60/98)\u001b[K\rremote: Compressing objects:  62% (61/98)\u001b[K\rremote: Compressing objects:  63% (62/98)\u001b[K\rremote: Compressing objects:  64% (63/98)\u001b[K\rremote: Compressing objects:  65% (64/98)\u001b[K\rremote: Compressing objects:  66% (65/98)\u001b[K\rremote: Compressing objects:  67% (66/98)\u001b[K\rremote: Compressing objects:  68% (67/98)\u001b[K\rremote: Compressing objects:  69% (68/98)\u001b[K\rremote: Compressing objects:  70% (69/98)\u001b[K\rremote: Compressing objects:  71% (70/98)\u001b[K\rremote: Compressing objects:  72% (71/98)\u001b[K\rremote: Compressing objects:  73% (72/98)\u001b[K\rremote: Compressing objects:  74% (73/98)\u001b[K\rremote: Compressing objects:  75% (74/98)\u001b[K\rremote: Compressing objects:  76% (75/98)\u001b[K\rremote: Compressing objects:  77% (76/98)\u001b[K\rremote: Compressing objects:  78% (77/98)\u001b[K\rremote: Compressing objects:  79% (78/98)\u001b[K\rremote: Compressing objects:  80% (79/98)\u001b[K\rremote: Compressing objects:  81% (80/98)\u001b[K\rremote: Compressing objects:  82% (81/98)\u001b[K\rremote: Compressing objects:  83% (82/98)\u001b[K\rremote: Compressing objects:  84% (83/98)\u001b[K\rremote: Compressing objects:  85% (84/98)\u001b[K\rremote: Compressing objects:  86% (85/98)\u001b[K\rremote: Compressing objects:  87% (86/98)\u001b[K\rremote: Compressing objects:  88% (87/98)\u001b[K\rremote: Compressing objects:  89% (88/98)\u001b[K\rremote: Compressing objects:  90% (89/98)\u001b[K\rremote: Compressing objects:  91% (90/98)\u001b[K\rremote: Compressing objects:  92% (91/98)\u001b[K\rremote: Compressing objects:  93% (92/98)\u001b[K\rremote: Compressing objects:  94% (93/98)\u001b[K\rremote: Compressing objects:  95% (94/98)\u001b[K\rremote: Compressing objects:  96% (95/98)\u001b[K\rremote: Compressing objects:  97% (96/98)\u001b[K\rremote: Compressing objects:  98% (97/98)\u001b[K\rremote: Compressing objects: 100% (98/98)\u001b[K\rremote: Compressing objects: 100% (98/98), done.\u001b[K\n",
            "remote: Total 102 (delta 47), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects:   0% (1/102)   \rReceiving objects:   1% (2/102)   \rReceiving objects:   2% (3/102)   \rReceiving objects:   3% (4/102)   \rReceiving objects:   4% (5/102)   \rReceiving objects:   5% (6/102)   \rReceiving objects:   6% (7/102)   \rReceiving objects:   7% (8/102)   \rReceiving objects:   8% (9/102)   \rReceiving objects:   9% (10/102)   \rReceiving objects:  10% (11/102)   \rReceiving objects:  11% (12/102)   \rReceiving objects:  12% (13/102)   \rReceiving objects:  13% (14/102)   \rReceiving objects:  14% (15/102)   \rReceiving objects:  15% (16/102)   \rReceiving objects:  16% (17/102)   \rReceiving objects:  17% (18/102)   \rReceiving objects:  18% (19/102)   \rReceiving objects:  19% (20/102)   \rReceiving objects:  20% (21/102)   \rReceiving objects:  21% (22/102)   \rReceiving objects:  22% (23/102)   \rReceiving objects:  23% (24/102)   \rReceiving objects:  24% (25/102)   \rReceiving objects:  25% (26/102)   \rReceiving objects:  26% (27/102)   \rReceiving objects:  27% (28/102)   \rReceiving objects:  28% (29/102)   \rReceiving objects:  29% (30/102)   \rReceiving objects:  30% (31/102)   \rReceiving objects:  31% (32/102)   \rReceiving objects:  32% (33/102)   \rReceiving objects:  33% (34/102)   \rReceiving objects:  34% (35/102)   \rReceiving objects:  35% (36/102)   \rReceiving objects:  36% (37/102)   \rReceiving objects:  37% (38/102)   \rReceiving objects:  38% (39/102)   \rReceiving objects:  39% (40/102)   \rReceiving objects:  40% (41/102)   \rReceiving objects:  41% (42/102)   \rReceiving objects:  42% (43/102)   \rReceiving objects:  43% (44/102)   \rReceiving objects:  44% (45/102)   \rReceiving objects:  45% (46/102)   \rReceiving objects:  46% (47/102)   \rReceiving objects:  47% (48/102)   \rReceiving objects:  48% (49/102)   \rReceiving objects:  49% (50/102)   \rReceiving objects:  50% (51/102)   \rReceiving objects:  51% (53/102)   \rReceiving objects:  52% (54/102)   \rReceiving objects:  53% (55/102)   \rReceiving objects:  54% (56/102)   \rReceiving objects:  55% (57/102)   \rReceiving objects:  56% (58/102)   \rReceiving objects:  57% (59/102)   \rReceiving objects:  58% (60/102)   \rReceiving objects:  59% (61/102)   \rReceiving objects:  60% (62/102)   \rReceiving objects:  61% (63/102)   \rReceiving objects:  62% (64/102)   \rReceiving objects:  63% (65/102)   \rReceiving objects:  64% (66/102)   \rReceiving objects:  65% (67/102)   \rReceiving objects:  66% (68/102)   \rReceiving objects:  67% (69/102)   \rReceiving objects:  68% (70/102)   \rReceiving objects:  69% (71/102)   \rReceiving objects:  70% (72/102)   \rReceiving objects:  71% (73/102)   \rReceiving objects:  72% (74/102)   \rReceiving objects:  73% (75/102)   \rReceiving objects:  74% (76/102)   \rReceiving objects:  75% (77/102)   \rReceiving objects:  76% (78/102)   \rReceiving objects:  77% (79/102)   \rReceiving objects:  78% (80/102)   \rReceiving objects:  79% (81/102)   \rReceiving objects:  80% (82/102)   \rReceiving objects:  81% (83/102)   \rReceiving objects:  82% (84/102)   \rReceiving objects:  83% (85/102)   \rReceiving objects:  84% (86/102)   \rReceiving objects:  85% (87/102)   \rReceiving objects:  86% (88/102)   \rReceiving objects:  87% (89/102)   \rReceiving objects:  88% (90/102)   \rReceiving objects:  89% (91/102)   \rReceiving objects:  90% (92/102)   \rReceiving objects:  91% (93/102)   \rReceiving objects:  92% (94/102)   \rReceiving objects:  93% (95/102)   \rReceiving objects:  94% (96/102)   \rReceiving objects:  95% (97/102)   \rReceiving objects:  96% (98/102)   \rReceiving objects:  97% (99/102)   \rReceiving objects:  98% (100/102)   \rReceiving objects:  99% (101/102)   \rReceiving objects: 100% (102/102)   \rReceiving objects: 100% (102/102), 26.93 KiB | 2.99 MiB/s, done.\n",
            "Resolving deltas:   0% (0/47)   \rResolving deltas:  10% (5/47)   \rResolving deltas:  23% (11/47)   \rResolving deltas:  34% (16/47)   \rResolving deltas:  42% (20/47)   \rResolving deltas:  48% (23/47)   \rResolving deltas:  68% (32/47)   \rResolving deltas:  82% (39/47)   \rResolving deltas:  85% (40/47)   \rResolving deltas:  89% (42/47)   \rResolving deltas:  91% (43/47)   \rResolving deltas:  95% (45/47)   \rResolving deltas: 100% (47/47)   \rResolving deltas: 100% (47/47), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvtfv0JpORiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im53LJDTvHhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "\n",
        "#package to add PySpark to sys.path at runtime\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RweI83-YFkiz",
        "colab_type": "text"
      },
      "source": [
        "# Mount the Google Drive so we can use data storage for inputs and outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSHKkmm2twAD",
        "colab_type": "code",
        "outputId": "254f35f8-340e-4754-eccc-144d19d3ef24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aXjRyP9Z987",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MMX_Wxaqkr5",
        "colab_type": "text"
      },
      "source": [
        "# Class PUBLIC_LOAN_FNMA_spark. \n",
        "\n",
        "## Re-implementation of  PUBLIC_LOAN_FNMA using **pyspark** API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g09mFAJzyUYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "#cannot import name 'monotonically_increasing_id'\n",
        "from pyspark.sql import functions as F,  Window\n",
        "##from pyspark.sql.functions import col, udf, to_date, when, collect_list, lag,  max, row_number, monotonically_increasing_id\n",
        "from pyspark.sql.types import DateType, StructType, StructField,  DoubleType, FloatType, IntegerType, LongType, StringType, DateType\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "class PUBLIC_LOAN_FNMA_spark(PUBLIC_LOAN_FNMA):\n",
        "    '''processing public loan data from Fannie Mae '''\n",
        "      #schema of Acquisition Data\n",
        "    \n",
        "    def __init__(self, acqYYYYQQ, stageFolder=None,  acquisition_file=None, performance_file=None):\n",
        "         super().__init__(acqYYYYQQ, stageFolder    , acquisition_file, performance_file)\n",
        "         \n",
        "\n",
        "    @staticmethod\n",
        "    def convTypeToSpark(v):\n",
        "          vout = StringType()\n",
        "          dtype = v.get('dtype')\n",
        "          if dtype == \"float\":\n",
        "             vout = FloatType()\n",
        "          elif dtype == \"double\":\n",
        "            vout = DoubleType()\n",
        "          elif dtype  == \"int\":\n",
        "            vout = IntegerType()\n",
        "          elif dtype  == \"string\":\n",
        "            vout = StringType()\n",
        "          elif dtype == \"date\":\n",
        "            vout = StringType()\n",
        "          else:\n",
        "            vout = StringType()\n",
        "          return vout\n",
        "\n",
        "    @staticmethod\n",
        "    def save_to_hive(dbname, tablename, dataframe_src):\n",
        "          #1. Creating Hive Database\n",
        "          spark.sql('create database IF NOT EXISTS ' + dbname)\n",
        "          spark.sql('use ' + dbname )\n",
        "          spark.sql(\"drop table IF  EXISTS \" + tablename)                                   \n",
        "          spark.sql(\"show tables\").show()\n",
        "\n",
        "          spark.sql(\"insert into table ratings \\\n",
        "                     select * from \" +dataframe_src )\n",
        "\n",
        "    def compute_schd_upb(self, monthCount, outAsMatrix=True):\n",
        "          '''\n",
        "          Calculate the scheduled UPB based on the Loan_Data[\"ORIG_AMT\", \"ORIG_RT\", \"ORIG_TRM\"]\n",
        "\n",
        "          Parameters\n",
        "          ----------\n",
        "          monthCount: int, sepcify the period to get UPB.\n",
        "          outformat : string, \"matrix\", \"pandas_df\", \"spark_df\"\n",
        "       \n",
        "          Returns\n",
        "          -------\n",
        "          out : ndarray (M, N),  spark dataframe\n",
        "          '''\n",
        "          sub_df = self.Loan_Data.select(\"LOAN_ID\", \"ORIG_AMT\", \"ORIG_RT\", \"ORIG_TRM\").toPandas()\n",
        "         \n",
        "          upb_matrix = super().compute_schd_upb(monthCount, outAsMatrix, sub_df)\n",
        "          \n",
        "          if outAsMatrix == True:\n",
        "             return upb_matrix\n",
        "          else:\n",
        "             return spark.createDataFrame(upb_matrix)\n",
        "        \n",
        "\n",
        "\n",
        "    def read_data_acquisition (self, acquisition_file=None):\n",
        "          '''\n",
        "          read and pre-process acqusition data\n",
        "          '''\n",
        "          if acquisition_file is not None:\n",
        "             self.acquisition_file = acquisition_file\n",
        "\n",
        "          # need to check file existing\n",
        "          ColumnSchema = StructType([StructField(k, PUBLIC_LOAN_FNMA_spark.convTypeToSpark(v), True) for k, v in self._AcquisitionSchema.items()])                   \n",
        "          ts = time.time()\n",
        "          acq_df = spark.read.format(\"csv\").options(header='False', delimiter=\"|\").schema(ColumnSchema).load(self.acquisition_file )\n",
        "          \n",
        "          for k, v in self._AcquisitionSchema.items():\n",
        "             if v.get('dtype') == \"date\":\n",
        "                acq_df = acq_df.withColumn(k,  F.to_date(F.col(k), v.get('format2')))\n",
        "             else:\n",
        "                value = v.get('default')\n",
        "                if value is not None:\n",
        "                   acq_df = acq_df.withColumn(k, F.when(F.col(k).isNull(), value).otherwise(F.col(k)))\n",
        "\n",
        "          acq_df = acq_df.withColumn('OCLTV',     F.expr(\"case when OCLTV ==0 then OLTV else OCLTV end\"))\n",
        "\n",
        "          for k, v in self._AcquisitionSchema.items():\n",
        "             if v.get('drop') == True:\n",
        "                acq_df= acq_df.drop(k)\n",
        "         \n",
        "          self.Loan_Data = acq_df\n",
        "          \n",
        "          return None\n",
        "\n",
        "    def read_data_performance (self, performance_file=None):\n",
        "          '''\n",
        "          read and pre-process acqusition data\n",
        "          '''\n",
        "          if performance_file is not None:\n",
        "             self.performance_file = performance_file\n",
        "\n",
        "          # need to check file existing\n",
        "          ColumnSchema = [StructField(k, PUBLIC_LOAN_FNMA_spark.convTypeToSpark(v), True) for k, v in self._PerformanceSchema.items()]\n",
        "          ColumnSchema = StructType(ColumnSchema)                                \n",
        "\n",
        "          #udf\n",
        "          #str_to_date =  udf (lambda x: datetime.strptime(x, '%m/%Y'), DateType())   \n",
        "          windowIncF12 =  Window().partitionBy(\"LOAN_ID\").orderBy(\"ACT_DTE\").rowsBetween(1, 12)\n",
        "          windowIncF24 =  Window().partitionBy(\"LOAN_ID\").orderBy(\"ACT_DTE\").rowsBetween(1, 24)\n",
        "          windowIncP12 =  Window().partitionBy(\"LOAN_ID\").orderBy(\"ACT_DTE\").rowsBetween(-12, -1)\n",
        "          windowInc    =  Window().partitionBy(\"LOAN_ID\").orderBy(\"ACT_DTE\")\n",
        "\n",
        "          ts = time.time()\n",
        "          per_df = spark.read.format(\"csv\").options(header='False', delimiter=\"|\").schema(ColumnSchema).load(self.performance_file )\n",
        "          #per_df.show(10)\n",
        "          print(\"read cvs: \", showtime(ts))\n",
        "        \n",
        "          ts = time.time()\n",
        "          # date columnd\n",
        "          for k, v in self._PerformanceSchema.items():\n",
        "             if v.get('dtype') == \"date\":\n",
        "                per_df = per_df.withColumn(k,  F.to_date(F.col(k), v.get('format2')))\n",
        "\n",
        "          per_df = per_df.withColumn('DLQ_STATUS', F.when(F.col('DLQ_STATUS').isNull(), -1).when(F.col('DLQ_STATUS') == \"X\", -2).otherwise(F.col('DLQ_STATUS').cast(IntegerType())))\n",
        "          per_df = per_df.withColumn('DEFT_COST',  F.expr(\"FCC_COST + PP_COST + AR_COST + IE_COST + TAX_COST\"))\n",
        "          per_df = per_df.withColumn('DEFT_PROCS',  F.expr(\"NS_PROCS + CE_PROCS + RMW_PROCS + O_PROCS\"))\n",
        "\n",
        "          per_df = per_df.withColumn(\"DLQ_LAG\", F.lag('DLQ_STATUS', 1).over(windowInc)) \\\n",
        "              .withColumn(\"DLQ_LAGs12\",         F.collect_list('DLQ_STATUS').over(windowIncP12)) \\\n",
        "              .withColumn(\"DLQ_NEXT12MAX\",      F.max('DLQ_STATUS').over(windowIncF12)) \\\n",
        "              .withColumn(\"DLQ_NEXT24MAX\",      F.max('DLQ_STATUS').over(windowIncF24)) \\\n",
        "              .withColumn(\"ZBCODE_NEXT12\",      F.max('ZB_CODE').over(windowIncF12)) \\\n",
        "              .withColumn(\"ZBCODE_NEXT24\",      F.max('ZB_CODE').over(windowIncF24)) \\\n",
        "              .withColumn(\"MOD_NEXT12\",         F.max('MOD_FLAG').over(windowIncF12)) \\\n",
        "              .withColumn(\"MOD_NEXT24\",         F.max('MOD_FLAG').over(windowIncF24)) \n",
        "\n",
        "          print(per_df.printSchema())\n",
        "          \n",
        "          print(\"transform: \", showtime(ts))\n",
        "        \n",
        "          ts = time.time()\n",
        "          Mod_DF = per_df.filter(F.col(\"MOD_FLAG\")=='Y').withColumn(\"rn\", F.row_number().over(windowInc)).where((F.col(\"rn\") ==1)) \\\n",
        "                      .select(\"LOAN_ID\", \n",
        "                              F.col(\"ACT_DTE\").alias(\"MOD_DTE\"), \n",
        "                              F.col(\"LOAN_AGE\").alias(\"MOD_AGE\"), \n",
        "                              F.col(\"DLQ_STATUS\").alias(\"MOD_DLQ\"),\n",
        "                              F.col(\"DLQ_LAG\").alias(\"MOD_DLQ_LAG\"),\n",
        "                              F.col(\"DLQ_LAGs12\").alias(\"MOD_DLQ_LAGs12\"),\n",
        "                              F.col(\"DLQ_NEXT12MAX\").alias(\"MOD_POST_MAXDLQ_12\"),\n",
        "                              F.col(\"DLQ_NEXT24MAX\").alias(\"MOD_POST_MAXDLQ_24\"),\n",
        "                              F.col(\"ZBCODE_NEXT12\").alias(\"MOD_POST_ZBCODE_12\"),\n",
        "                              F.col(\"ZBCODE_NEXT24\").alias(\"MOD_POST_ZBCODE_24\")\n",
        "                              )\n",
        "          print(\"Mod DF: \", showtime(ts))\n",
        "        \n",
        "          ts = time.time()\n",
        "          F3Q_DF = per_df.filter(F.col(\"DLQ_STATUS\")>2).withColumn(\"rn\", F.row_number().over(windowInc)).where((F.col(\"rn\") ==1)) \\\n",
        "                     .select(\"LOAN_ID\", \n",
        "                              F.col(\"ACT_DTE\").alias(\"F3Q_DTE\"), \n",
        "                              F.col(\"LOAN_AGE\").alias(\"F3Q_AGE\"), \n",
        "                              F.col(\"DLQ_LAGs12\").alias(\"F3Q_DLQ_LAGs12\"),\n",
        "                              F.col(\"DLQ_NEXT12MAX\").alias(\"F3Q_POST_MAXDLQ_12\"),\n",
        "                              F.col(\"DLQ_NEXT24MAX\").alias(\"F3Q_POST_MAXDLQ_24\"),\n",
        "                              F.col(\"ZBCODE_NEXT12\").alias(\"F3Q_POST_ZBCODE_12\"),\n",
        "                              F.col(\"ZBCODE_NEXT24\").alias(\"F3Q_POST_ZBCODE_24\")\n",
        "                              )\n",
        "          print(\"F3Q DF: \", showtime(ts))\n",
        "        \n",
        "          ts = time.time()\n",
        "          ZB_DF = per_df.filter(F.col(\"ZB_CODE\").isNotNull()) \\\n",
        "                    .select(\"LOAN_ID\", \"ZB_CODE\", \"ZB_DTE\",\n",
        "                              F.col(\"LOAN_AGE\").alias(\"ZB_AGE\"), \n",
        "                              F.col(\"DLQ_LAGs12\").alias(\"ZB_DLQ_LAGs12\"),\n",
        "                              F.col(\"DLQ_LAG\").alias(\"ZB_DLQ_LAG\"),\n",
        "                              F.col(\"LAST_UPB\").alias(\"ZB_LAST_UPB\"),\n",
        "                              \"LPI_DTE\",\n",
        "                              \"FCC_DTE\",\n",
        "                              \"DISP_DTE\", \"DEFT_COST\", \"DEFT_PROCS\"\n",
        "                    )\n",
        "          print(\"ZB DF: \", showtime(ts))\n",
        "        \n",
        "          ts = time.time()\n",
        "\n",
        "          if self.Loan_Data is None:\n",
        "             loanLevelDF =  Mod_DF.select(\"LOAN_ID\") \\\n",
        "                     .union(F3Q_DF.select(\"LOAN_ID\")) \\\n",
        "                     .union( ZB_DF.select(\"LOAN_ID\")).distinct()\n",
        "          \n",
        "             loanLevelDF = loanLevelDF.join(Mod_DF, \"LOAN_ID\", how=\"left\")\n",
        "             loanLevelDF = loanLevelDF.join(F3Q_DF, \"LOAN_ID\", how=\"left\")\n",
        "             loanLevelDF = loanLevelDF.join(ZB_DF,  \"LOAN_ID\",  how=\"left\") \n",
        "          else:\n",
        "             self.Loan_Data = self._Loan_Data.join(Mod_DF, \"LOAN_ID\", how=\"left\") \\\n",
        "                                         .join(F3Q_DF, \"LOAN_ID\", how=\"left\") \\\n",
        "                                         .join(ZB_DF,  \"LOAN_ID\",  how=\"left\").orderBy([\"LOAN_ID\"])\n",
        "              \n",
        "          print(\"join: \", showtime(ts))\n",
        "          select_col = [k for k, v in self._PerformanceSchema.items() if v.get(\"drop\", False) == False]\n",
        "          Performance_Data = per_df.select(select_col)\n",
        "\n",
        "          #calcualte schd_upb\n",
        "          age_max = 12  #Performance_Data.agg({\"LOAN_AGE\": \"max\"}).first()[0]\n",
        "          ts = time.time()\n",
        "          schd_upbData = self.compute_schd_upb(monthCount=age_max, outAsMatrix=False)\n",
        "          print(\"compute upb: \", showtime(ts))\n",
        "         \n",
        "          ts = time.time()\n",
        "          self.Performance_Data = Performance_Data.join(schd_upbData, on=[\"LOAN_ID\", \"LOAN_AGE\"], how=\"left\").orderBy([\"LOAN_ID\",  \"ACT_DTE\"])\n",
        "          print(\"joining upb: \", showtime(ts))\n",
        "          ts = time.time()\n",
        "          self.Performance_Data = self.Performance_Data.filter(F.col(\"LOAN_AGE\")>=0).withColumn(\"LAST_UPB\",  F.expr(\"case when LAST_UPB is Null then round(SCHD_UPB,3) else LAST_UPB end\") )\n",
        "          self.Performance_Data=  self.Performance_Data.drop(\"SCHD_UPB\")\n",
        "          print(\"filtering out: \", showtime(ts))\n",
        "           \n",
        "          return None\n",
        "\n",
        "\n",
        "def _test():\n",
        "    import doctest\n",
        "    from pyspark.context import SparkContext\n",
        "    from pyspark.sql import SparkSession\n",
        "    from pyspark.sql.types import StructType, StructField\n",
        "    from pyspark.sql.types import DoubleType, LongType, StringType, DateType\n",
        "    globs = globals()\n",
        "    spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
        "    sc = spark.sparkContext\n",
        "    globs['sc'] = sc\n",
        "    globs['spark'] = spark\n",
        "   \n",
        "  \n",
        "    myobj = PUBLIC_LOAN_FNMA_spark(acqYYYYQQ = \"2000Q1\", stageFolder = \"/content/drive/My Drive/ML_Data/stock\",\n",
        "                                   acquisition_file = \"/content/drive/My Drive/ML_Data/stock/Acquisition_2000Q1.txt\",\n",
        "                                   performance_file = \"/content/drive/My Drive/ML_Data/stock/Performance_2000Q1.txt\" )\n",
        "    myobj.read_data_acquisition()\n",
        "    myobj.read_data_performance()\n",
        "    myobj.save_as_parquet(resultFolder=\"/content/drive/My Drive/ML_Data\")\n",
        "\n",
        "    #if (scenario == 0):\n",
        "    #  myobj.read_data_acquisition(\"/content/drive/My Drive/ML_Data/stock/Acquisition_2000Q1.txt\")\n",
        "    #  mydata = myobj.Loan_Data\n",
        "    #  mydata.show(100)\n",
        "      #acq_df = spark.read.parquet(\"output/FNMA/LoanAcq.parquet\")\n",
        "      #acq_df.createOrReplaceTempView(\"acq_df_table\")\n",
        "      #a = spark.sql(\"select case when ORIG_CHN in ('R', 'C') then 'R1' when ORIG_CHN == 'B' then 'B1' else ORIG_CHN end as K, ORIG_CHN from acq_df_table where OCLTV is not null  \")\n",
        "      #a = spark.sql(\"select * from acq_df_table where ACQ = '\" + mydata.acqYYYYQQ + \"' limit 10\")\n",
        "      #a.show()\n",
        "      #a.printSchema()\n",
        "      #a = spark.sql(\"select * from acq_df_table order by  LOAN_ID, ACQ  limit 10\")\n",
        "      #a.show()\n",
        "     \n",
        "      #a = spark.sql(\"select count(*) from acq_df_table \") #where ACQ = '\" + mydata.acqYYYYQQ + \"' \")\n",
        "      #a.toPandas().head(100)\n",
        "     \n",
        "    #else:\n",
        "    #  mydata = myobj.read_data_performance(\"/content/drive/My Drive/ML_Data/stock/Performance_2000Q1.txt\")\n",
        "    #  mydata.show(100)\n",
        "      #per_df = spark.read.parquet(\"output/FNMA/LoanPerformance.parquet\")\n",
        "      #per_df.createOrReplaceTempView(\"per_df_table\")\n",
        "      #a = spark.sql(\"select case when ORIG_CHN in ('R', 'C') then 'R1' when ORIG_CHN == 'B' then 'B1' else ORIG_CHN end as K, ORIG_CHN from acq_df_table where OCLTV is not null  \")\n",
        "      #a = spark.sql(\"select * from per_df_table  limit 10\")\n",
        "      #a.show()\n",
        "      #a.printSchema()\n",
        "    return (myobj)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    acqData = _test()\n",
        "    acqData.Loan_Data.show(10)\n",
        "    acqData.Performance_Data.show(100)\n",
        "    '''\n",
        "    per_df = spark.read.parquet(\"output/FNMA/LoanPerformance.parquet\")\n",
        "    wInc =  Window().partitionBy(\"LOAN_ID\").orderBy(col(\"ACT_DTE\"))\n",
        "    postMod12 = per_df.filter(col(\"MOD_FLAG\")=='Y').withColumn(\"rn\", row_number().over(wInc)).where((col(\"rn\") ==1))\n",
        "    post3Q12 = per_df.filter(col(\"DLQ_STATUS\")>2).withColumn(\"rn\", row_number().over(wInc)).where((col(\"rn\") ==1))\n",
        "    postMod12.show(100)\n",
        "    post3Q12.show(100)\n",
        " '''\n",
        "    #wDesc = Window().partitionBy(\"LOAN_ID\").orderBy(col(\"ACT_DTE\").desc())\n",
        "    #a = per_df.filter(col(\"MOD_FLAG\")=='Y').withColumn(\"rn\", row_number().over(w)).where((col(\"rn\") <3))\n",
        "    #per_df.createOrReplaceTempView(\"per_df_table\")\n",
        "    #a = spark.sql(\"select  * from per_df_table where DLQ_STATUS is  null\")\n",
        "    #a.show(100)\n",
        "    #aa = spark.sql(\"select  * from per_df_table where LOAN_ID in ('254323574864', '254461287100') or DLQ_STATUS='X' \")\n",
        "    #aa.show(300)\n",
        "    '''\n",
        "    1.Find the first 3D\n",
        "    2.Find the first mod and type\n",
        "    3.Find the next 12/24 months, MAX DLQ or ZB_CODE\n",
        "    4.Given ZB_CODE is not null, what is the DLQ_STATUS at the previous month.\n",
        "    '''\n",
        "    #w = Window().partitionBy(\"LOAN_ID\").orderBy(col(\"ACT_DTE\").desc())\n",
        "    #d = per_df.filter().withColumn(\"rn\", row_number().over(w)).where((col(\"rn\") == 1) | (col(\"rn\") == 2)).select(\"LOAN_ID\", \"ACT_DTE\", \"rn\")\n",
        "    #d.show(100)\n",
        "\n",
        "#w = Window().partitionBy(\"store_product_id\").orderBy(col(\"time_create\").desc())\n",
        "#(df\n",
        "#  .withColumn(\"rn\", row_number().over(w))\n",
        "#  .where(col(\"rn\") == 1)\n",
        "#  .select(\"store_product_id\", \"time_create\", \"state\"))\n",
        "\n",
        "    #per_df.createOrReplaceTempView(\"per_df_table\")\n",
        "    #a = spark.sql(\"select case when ORIG_CHN in ('R', 'C') then 'R1' when ORIG_CHN == 'B' then 'B1' else ORIG_CHN end as K, ORIG_CHN from acq_df_table where OCLTV is not null  \")\n",
        "    #a = spark.sql(\"select  * from per_df_table where LPI_DTE is not null limit 100\")\n",
        "    #a.show()\n",
        "#a = spark.sql(\"select * from per_df_table where ZB_CODE='09' limit 1000\")\n",
        "#a.show()\n",
        "#a.printSchema()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o60PHjUd9Mc",
        "colab_type": "code",
        "outputId": "1d1c9e2c-fc58-4669-a603-55c835325c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "source": [
        "acqData.Performance_Data.filter(\"LOAN_AGE < 0\").select(\"LOAN_ID\", \"ACT_DTE\",\"LOAN_AGE\",  \"LAST_UPB\", \"SCHD_UPB\", \"DLQ_STATUS\").show(2000)\n",
        "round(15.555533355, 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+--------+--------+--------+----------+\n",
            "|LOAN_ID|ACT_DTE|LOAN_AGE|LAST_UPB|SCHD_UPB|DLQ_STATUS|\n",
            "+-------+-------+--------+--------+--------+----------+\n",
            "+-------+-------+--------+--------+--------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.556"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubOOVlwD5D2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3DECpTrVokK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pfile = \"output/FNMA/LoanPerformance.parquet\"\n",
        "pfile = \"output/FNMA/LL_LoanPerformance.parquet\"\n",
        "ts = time.time()\n",
        "data = pd.read_parquet(pfile)\n",
        "#print(data)\n",
        "\n",
        "#print(data.info())\n",
        "\n",
        "#mdata = data[data.ZB_AGE  >0]\n",
        "\n",
        "#mm = data.DLQ_LAGs12.to_numpy()\n",
        "#print(mm)\n",
        "#print(type(mm))\n",
        "#print(\"transform: \" , showtime(ts))\n",
        "'''\n",
        "ts = time.time()\n",
        "per_df = spark.read.parquet(pfile)\n",
        "per_df.printSchema()\n",
        "#per_df.show(300)\n",
        "print(\"transform: \" , showtime(ts))\n",
        "print(data.info())\n",
        "my = per_df.select(\"ZB_DLQ_LAGs12\").flat()\n",
        "\n",
        "my.show(10)\n",
        "'''\n",
        "\n",
        "\n",
        "def convert_array_elements_as_dataframe(df, colname, requested_size):\n",
        " \n",
        "    #V = df[colname].apply(lambda x: [] if x== np.NaN else x)\n",
        "    df[colname].fillna(\"\", inplace=True)\n",
        "    df[colname + \"_OrigSize\"] = df[colname].apply(lambda x: len(x))\n",
        "    V = df[colname].apply(lambda x: (([-1]*(12-len(x))) + list(x)) if   len(x) < 12 else x  )\n",
        "    V =V.to_numpy().flatten()\n",
        "    V = np.vstack(V)\n",
        "    result_df = pd.DataFrame(V)\n",
        "    result_df[\"LOAN_ID\"] = df[\"LOAN_ID\"]\n",
        "\n",
        "    df = pd.merge(df, result_df, how=\"inner\", on=\"LOAN_ID\")\n",
        "    return (df)\n",
        "    \n",
        "\n",
        "v = convert_array_elements_as_dataframe(data, \"F3Q_DLQ_LAGs12\", 12)\n",
        "\n",
        "R = v.query(\"F3Q_AGE <12 \")\n",
        "#data[ ((data[\"F3Q_AGE\"] > 0) & (data[\"F3Q_AGE\"] < 12)) ][[\"LOAN_ID\", \"F3Q_DLQ_LAGs12\"]]\n",
        "#mydata = data.loc[ ((data[\"F3Q_AGE\"] > 0) & (data[\"F3Q_AGE\"] < 12)) ,[\"LOAN_ID\", \"F3Q_DLQ_LAGs12\"]]\n",
        "#mydata[\"NumSize\"] = mydata[\"F3Q_DLQ_LAGs12\"].apply(lambda x: len(x))\n",
        "\n",
        "#mydata[\"F3Q_DLQ_LAGs12\"] = mydata[\"F3Q_DLQ_LAGs12\"].apply(lambda x: (([-1]*(12-len(x))) + list(x)) if len(x) < 12 else x  )\n",
        "\n",
        "\n",
        "#mydata[[\"F3Q_DLQ_LAGs12\"]]\n",
        "\n",
        "\n",
        "\n",
        "#dd = mydata[[\"F3Q_DLQ_LAGs12\"]].to_numpy().flatten()\n",
        "#dd = np.vstack(dd)\n",
        "#print(dd.shape)\n",
        "#m =[]\n",
        "#for d in dd:\n",
        "#   m.append(list(d))\n",
        "\n",
        "#print(m.flatten())\n",
        "#mm = np.concatenate(m)\n",
        "#print(\"DDDDDDD\")\n",
        "#print(mm)\n",
        "#print(mm.shape)\n",
        "\n",
        "#a = mydata.to_numpy().apply(lambda x: pd.DataFrame({\"A\": x[0], \"B\": x[1]}), axis=1 ) #[\"LOAN_ID\"], x[\"F3Q_DLQ_LAGs12\"]))\n",
        "\n",
        "#print(type(a))\n",
        "\n",
        "#pa=pd.DataFrame({'a':[[1.,4.],  [2.],             [3.,4.,5.]]})\n",
        "#Q = pa.to_numpy().flatten()\n",
        "#print(Q)\n",
        "\n",
        "R"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suygpFAN0GeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install numpy_financial\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy_financial as npf\n",
        "import time\n",
        "\n",
        "pfile = \"output/FNMA/LoanAcq.parquet\"\n",
        "ts = time.time()\n",
        "\n",
        "#gapminder.assign(pop_in_millions=lambda x: x['pop']/1e6,\n",
        "#                pop_in_billions=lambda x: x['pop_in_millions']/1e3).head()\n",
        "\n",
        "ts = time.time()\n",
        "data = pd.read_parquet(pfile)\n",
        "print(\"read_parquet: \" , showtime(ts))\n",
        "print(data[\"ORIG_RT\"][1:10])\n",
        "\n",
        "#@timeit2\n",
        "def test1(data):\n",
        "    def compute_schd_upb(self, rates, num_months, principals, max_month = None):\n",
        "        print(f\"{principals[0]} : {num_months[0]} : {rates[0]*1200}\")\n",
        "        print(f\"{principals[1]} : {num_months[1]} : {rates[1]*1200}\")\n",
        "        #expect acq_data is a pandas dataframe, having fields\n",
        "        #   LOAN_ID, ORIG_RT, ORIG_AMT, ORIG_TRM\n",
        "        num_loans = rates.count()\n",
        "      \n",
        "        #using numpy array for now\n",
        "        num_month = num_months.max()\n",
        "\n",
        "        if max_month is not None:\n",
        "           num_month = max(1, max_month)\n",
        "\n",
        "        upb_matrix = np.zeros((num_loans, num_month))\n",
        "        upb_matrix[:, 0] = principals\n",
        "        for i in range(1, num_month):\n",
        "            p_payment = -npf.ppmt(rate =rates , per=i, nper=num_months, pv= principals)\n",
        "            upb_matrix[:, i] =  upb_matrix[:, i-1] -  p_payment\n",
        "\n",
        "        return upb_matrix\n",
        "     \n",
        "    \n",
        "    r = compute_schd_upb(0, rates      = data[\"ORIG_RT\"] / 1200,\n",
        "                            num_months = data[\"ORIG_TRM\"],\n",
        "                            principals = data[\"ORIG_AMT\"] )\n",
        "    #print(r[1, 0:185])\n",
        "    return r.shape\n",
        "\n",
        "#@timeit2\n",
        "def test2(data):\n",
        "   \n",
        "    def compute_schd_upb(self, rates, num_months, principals, max_month = None):\n",
        "        \n",
        "        #print(f\"{principals[0]} : {num_months[0]} : {rates[0]*1200}\")\n",
        "        #print(f\"{principals[1]} : {num_months[1]} : {rates[1]*1200}\")\n",
        "        #expect acq_data is a pandas dataframe, having fields\n",
        "        #   LOAN_ID, ORIG_RT, ORIG_AMT, ORIG_TRM\n",
        "        num_loans = rates.count()\n",
        "        #using numpy array for now\n",
        "        num_month = num_months.max()\n",
        "\n",
        "        if max_month is not None:\n",
        "           num_month = max(1, max_month)\n",
        "\n",
        "        upb_matrix = np.zeros((num_loans, num_month))\n",
        "        upb_matrix[:, 0] = principals\n",
        "        total_payments = principals * (rates / (1 - (1 + rates) ** (-num_months)))\n",
        "        for i in range(1, num_month):\n",
        "            #total_payments = principals * (rates / (1 - (1 + rates) ** (-num_months)))\n",
        "            p_payment = total_payments - upb_matrix[:, i-1]*rates\n",
        "            #p_payment = -npf.ppmt(rate =rates , per=i, nper=num_months, pv= principals)\n",
        "            upb_matrix[:, i] =  upb_matrix[:, i-1] -  p_payment\n",
        "            #upb_matrix[:, i] =  upb_matrix[:, i-1] * (1+ rates) - total_payments\n",
        "        return upb_matrix\n",
        "     \n",
        "    \n",
        "    r = compute_schd_upb(0, rates      = data[\"ORIG_RT\"] / 1200,\n",
        "                            num_months = data[\"ORIG_TRM\"],\n",
        "                            principals = data[\"ORIG_AMT\"] )\n",
        "    #print(r[1, 1:20])\n",
        "    return r.shape\n",
        "\n",
        "def compute_amortization(principals, monthly_rates, terms,  start_period = 0, end_period = None):\n",
        "    \"\"\"\n",
        "    Compute amortization of loans\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    principals : scalar or array_like of shape(M, )\n",
        "        pricipals of loans\n",
        "    monthly_rates: scalar or array_like if  principals is a scalar\n",
        "                   or\n",
        "                   array_like or matrix_like if principals is an array_like\n",
        "        For FRM, one Rate for each loan\n",
        "        For ARM, one full time series for each loan\n",
        "    \n",
        "    terms:  scalar or array_like of shape(M, )\n",
        "    loan terms, type should match that of principals\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    out : ndarray (M, N)\n",
        "\n",
        "    \"\"\"\n",
        "    num_loans = 1\n",
        "    if isinstance(principals, pd.Series):\n",
        "       principals = principals.values\n",
        "    elif np.ndim(principals) == 0:\n",
        "       principals = [principals]\n",
        "    #assume principals is np.array\n",
        "    num_loans = len(principals)\n",
        "\n",
        "    if isinstance(monthly_rates, pd.Series):\n",
        "       monthly_rates = monthly_rates.values\n",
        "    elif np.ndim(principals) == 0:\n",
        "       monthly_rates = [monthly_rates]\n",
        "\n",
        "    if isinstance(terms, pd.Series):\n",
        "       terms = terms.values\n",
        "    elif np.ndim(terms) == 0:\n",
        "       terms = [terms]\n",
        "    \n",
        "    num_month = terms.max()\n",
        "    mini_term = terms.min()\n",
        "    if end_period is not None:\n",
        "      num_month = min(num_month, max(1, (end_period - start_period)))\n",
        "    \n",
        "    upb_matrix = np.zeros((num_month, num_loans))\n",
        "    the_payment = principals * (monthly_rates / (1 - (1 + monthly_rates) ** (-terms)))\n",
        "    \n",
        "    current_upb = principals\n",
        "    if start_period > 0:\n",
        "       current_upb = principals\n",
        "       for t in range(1, start_period+1):\n",
        "          pp_payment = the_payment - current_upb * monthly_rates\n",
        "          current_upb = current_upb - pp_payment\n",
        "    \n",
        "    upb_matrix[0, :] = current_upb\n",
        "      \n",
        "    i = 1\n",
        "    for t in range(start_period+1, start_period +num_month ):\n",
        "       isbeyondTerm = np.greater(t , terms)\n",
        "       pp_payment = the_payment - upb_matrix[i-1, :] * monthly_rates\n",
        "       upb_matrix[i, :] = (upb_matrix[i-1, :] - pp_payment) \n",
        "       if t >= mini_term:\n",
        "          iswithinTerm = np.greater( terms, t).astype(int)\n",
        "          isbeyondTerm = np.greater(t , terms).astype(int)\n",
        "          upb_matrix[i, :] = upb_matrix[i, :] * np.array(iswithinTerm) + (-999) * isbeyondTerm\n",
        "       i = i +  1\n",
        "    \n",
        "    ##post processing\n",
        "    #1, The UPB beyond its term is set to be -999\n",
        "    #i = 1\n",
        "    #for t in range(start_period+1, start_period +num_month ):\n",
        "    #   isbeyondTerm = np.greater(t , terms)\n",
        "    #   upb_matrix[i, :] = upb_matrix[i, :] + (-999) * np.array(isbeyondTerm)\n",
        "    #   i = i +  1\n",
        "\n",
        "    return upb_matrix.T\n",
        "\n",
        "\n",
        "%timeit cal_amortization(principals    = data[\"ORIG_AMT\"], \\\n",
        "                     monthly_rates = data[\"ORIG_RT\"] / 1200, \\\n",
        "                     terms         = data[\"ORIG_TRM\"])\n",
        "\n",
        "for i, x in enumerate(r[1, :]):\n",
        "  print(i, \"  \", x)\n",
        "#%timeit test2(data)\n",
        "'''\n",
        " 174         3,556.73     521.65     498.31      23.34       3,058.42\n",
        " 175         3,058.42     521.65     501.58      20.07       2,556.84\n",
        " 176         2,556.84     521.65     504.87      16.78       2,051.97\n",
        " 177         2,051.97     521.65     508.18      13.47       1,543.79\n",
        " 178         1,543.79     521.65     511.52      10.13       1,032.27\n",
        " 179         1,032.27     521.65     514.88       6.77         517.39\n",
        " 180           517.39     521.65     518.25       3.40          -0.86\n",
        "       \n",
        "  1         55,000.00     521.65     160.71     360.94      54,839.29\n",
        "  2         54,839.29     521.65     161.77     359.88      54,677.52\n",
        "  3         54,677.52     521.65     162.83     358.82      54,514.69\n",
        "  4         54,514.69     521.65     163.90     357.75      54,350.79\n",
        "  5      \n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF2jcT_uH1hk",
        "colab_type": "code",
        "outputId": "54e188c5-2c54-421b-cbe6-f4f694b96c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.greater(4,[5,2]) * -999"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0, -999])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clkn_2VO0jdv",
        "colab_type": "code",
        "outputId": "5f9edfea-a9e6-4eaf-8e7f-564c860c2655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from collections.abc import Sequence \n",
        "A =[pd.Series([1,2,3]),pd.Series([1,2,3])] \n",
        "K = isinstance(A, np.ndarray)\n",
        "\n",
        "B = np.array(A)\n",
        "K = isinstance(B, np.ndarray)\n",
        "K = isinstance(pd.Series([1,2,3]).values, np.ndarray)\n",
        "print(K)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl_w80f-eWeE",
        "colab_type": "text"
      },
      "source": [
        "**package: LoanPerformance**\n",
        "\n",
        "1. Processing public loan performance (from FNMA and FRED)\n",
        "\n",
        "2. Doing Amortization. (UPB)\n",
        " \n",
        " 2.1 FRM\n",
        "\n",
        " 2.2 ARM (flexible rate)\n",
        " https://files.consumerfinance.gov/f/201204_CFPB_ARMs-brochure.pdf\n",
        "\n",
        " * initial rate and payment\n",
        " * The adjustment period\n",
        " * The index\n",
        " * The margin\n",
        " * Interest-Rate Caps\n",
        " * Payment Caps\n",
        "\n",
        " * Type of ARMS\n",
        "  * Hybrid\n",
        "  * Interest-only\n",
        "  * Payment-option\n",
        "  * stepped\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "3. Rate incentive if IR is provided\n",
        "\n",
        "4. MTMLTV is HP is provided\n",
        "\n",
        "5. Predicting Prepayment, Default, DQL12.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Akb3tC7LhGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division, absolute_import, print_function\n",
        "r = 0.06/12\n",
        "n =240\n",
        "s = 150000\n",
        "p = r*s*(1+r)**(n) /(1-(1+r)**(n))\n",
        "p\n",
        "\n",
        "\n",
        "from decimal import *\n",
        "\n",
        "def amortization_table(principal, rate, term):\n",
        "    ''' Prints the amortization table for a loan.\n",
        "\n",
        "    Prints the amortization table for a loan given\n",
        "    the principal, the interest rate (as an APR), and\n",
        "    the term (in months).'''\n",
        "\n",
        "    payment = pmt(principal, rate, term)\n",
        "    begBal = principal\n",
        "\n",
        "    # Print headers\n",
        "    print ('Pmt no'.rjust(6), ' ', 'Beg. bal.'.ljust(13), ' ',  end = '')\n",
        "    print ('Payment'.ljust(9), ' ', 'Principal'.ljust(9), ' ',  end = '')\n",
        "    print ('Interest'.ljust(9), ' ', 'End. bal.'.ljust(13),  end = '')\n",
        "    print (''.rjust(6, '-'), ' ', ''.ljust(13, '-'), ' ',  end = '')\n",
        "    print (''.rjust(9, '-'), ' ', ''.ljust(9, '-'), ' ',  end = '')\n",
        "    print (''.rjust(9, '-'), ' ', ''.ljust(13, '-'), ' ')\n",
        "    # Print data\n",
        "    for num in range(1, term + 1):\n",
        "        \n",
        "        interest = round(begBal * (rate / (12 * 100.0)), 2)\n",
        "        applied = (payment - interest)\n",
        "        endBal = (begBal - applied)\n",
        "        \n",
        "        print (str(num).center(6), ' ',  end = '')\n",
        "        print ('{0:,.2f}'.format(begBal).rjust(13), ' ',  end = ''),\n",
        "        print ('{0:,.2f}'.format(payment).rjust(9), ' ', end = ''),\n",
        "        print ('{0:,.2f}'.format(applied).rjust(9), ' ',  end = ''),\n",
        "        print ('{0:,.2f}'.format(interest).rjust(9), ' ', end = ''),\n",
        "        print ('{0:,.2f}'.format(endBal).rjust(13))\n",
        "\n",
        "        begBal = endBal\n",
        "    \n",
        "def pmt(principal, rate, term):\n",
        "    '''Calculates the payment on a loan.\n",
        "\n",
        "    Returns the payment amount on a loan given\n",
        "    the principal, the interest rate (as an APR),\n",
        "    and the term (in months).'''\n",
        "    \n",
        "    ratePerTwelve = rate / (12 * 100.0)\n",
        "    \n",
        "    result = principal * (ratePerTwelve / (1 - (1 + ratePerTwelve) ** (-term)))\n",
        "\n",
        "    # Convert to decimal and round off to two decimal\n",
        "    # places.\n",
        "    result = (result)\n",
        "    #result = round(result, 2)\n",
        "    return result\n",
        "\n",
        "amortization_table(55000, 7.875, 180)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}